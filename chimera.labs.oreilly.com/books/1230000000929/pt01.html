<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">

<!-- Mirrored from chimera.labs.oreilly.com/books/1230000000929/pt01.html by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 19 Dec 2016 05:52:17 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><script type="text/javascript">var NREUMQ=NREUMQ||[];NREUMQ.push(["mark","firstbyte",new Date().getTime()]);</script>
	<title>Parallel and Concurrent Programming in Haskell</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link href="http://dwn0odqttrkhc.cloudfront.net/assets/book-f1caceafd9c9f3a6ff72d40c54d173ab.css" media="screen" rel="stylesheet" type="text/css" />
	<link href="http://dwn0odqttrkhc.cloudfront.net/assets/default-24583441b4f47382b8932338cd56ed23.css" media="screen" rel="stylesheet" type="text/css" />
	<script src="http://dwn0odqttrkhc.cloudfront.net/assets/application-47d6ffb0c77b868d29a43eb65e940505.js" type="text/javascript"></script>
	<script src="http://dwn0odqttrkhc.cloudfront.net/assets/book-756862b9ed04d945ca53de5b8f106a83.js" type="text/javascript"></script>
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	<link href="http://dwn0odqttrkhc.cloudfront.net/assets/janrain-53eb5abed55992e21943b9d3373923e8.css" media="all" rel="stylesheet" type="text/css" />
	<meta content="authenticity_token" name="csrf-param" />
<meta content="WQ02oEFDbvBG99rmf8rwvGssMqcy27cCD64yZVVTcMY=" name="csrf-token" />
	<script type="text/javascript" charset="utf-8">
  	
		app.data = new classes.Data({"controller":{"controller":"books","action":"html"},"capturable":{"capture_server":"https://oreilly.janraincapture.com","client_id":"6n5q2k9vesqgn93k3mhevka6c3c3rsre","app_url":"https://login.oreilly.com","app_id":"xsnca5wmqe9vxv97ygh5vfejkd","load_js":"d16s8pqtk4uodx.cloudfront.net/login.oreilly.com/load.js"},"user":{"id":null,"account":"LoggedOutAccount","email":"","name":null,"gravatar_url":"http://www.gravatar.com/avatar/d41d8cd98f00b204e9800998ecf8427e?s=40&d=identicon"},"book":{"isbn":"1230000000929","chapter":"pt01.html","toc_url":"/books/1230000000929/toc_html","metadata_url":"http://d4bb7yl96lyl1.cloudfront.net/1230000000929/metadata/metadata_9b2ac4d71a3220a7d463d8d4c80f9113048bb194.json"},"abilities":{"can_destroy_all_comments":false,"can_create_comments":false},"advertisement":{"body":"<style>      \r\n.ad-profile-image {\r\n  padding: 0;\r\n  margin: 0;\r\n  max-height: 30px;\r\n }\r\n\r\n.top-banner {\r\n  position: absolute;\r\n  right: 0;\r\n  top: 34px;\r\n  z-index: 99999;\r\n}\r\n\r\np.banner-text {\r\n  margin: 0;\r\n  text-align: center;\r\n  padding-right: 10px;\r\n  width: 450px;\r\n}\r\n\r\n@media screen and (max-width: 600px) {\r\n   p.banner-text {\r\n     width: 100%;\r\n     text-align: center;\r\n  }\r\n}\r\n\r\nspan.ebook-advantage {\r\n  font-size: smaller;\r\n  display: block;\r\n}\r\n\r\ndiv.banner-container {\r\n  margin: 0 auto;\r\n}\r\n\r\ndiv.banner-container ul {\r\n  margin: 0 auto;\r\n}\r\n\r\ndiv.topad { padding-bottom: 5px; }\r\n\r\ndiv.banner-container ul li {\r\n  display: inline-block;\r\n  vertical-align: middle;\r\n}\r\n\r\ndiv.banner-container li p {\r\n  padding-top: 0;\r\n  margin-top: 0;\r\n}\r\n\r\ndiv.banner-container li.sponsor {\r\n  border-right: 1px solid rgb(125, 154, 180);\r\n  margin-right: 5px;\r\n  padding-right: 10px;\r\n}\r\n\r\ndiv.banner-container .webbutton {\r\n  background-color: #3994b6;\r\n  display: inline-block;\r\n  padding: 10px;\r\n  -webkit-border-radius: 5px;\r\n  -moz-border-radius: 5px;\r\n  border-radius: 5px;\r\n  color: #FFF;\r\n  text-align: center;\r\n  text-decoration: none;\r\n  font-size: 12px;\r\n  font-weight: bold;\r\n}\r\n\r\n</style>\r\n   \r\n<div style=\"color: rgb(125, 154, 180);\">\r\n\r\n<div class=\"banner-container\">\r\n\r\n<ul>\r\n\r\n<li class=\"sponsor\">\r\n<!--CONFERENCE SPONSOR IMAGE-->\r\n<a href=\"http://www.oscon.com/oscon2013\">\r\n<!--<img src=\"http://orm-other.s3.amazonaws.com/fluent_logo.png\" class=\"ad-profile-image\"/>-->\r\n<img src=\"http://orm-other.s3.amazonaws.com/oscon_logo.png\" class=\"ad-profile-image\"/>\r\n<!--<img src=\"http://orm-other.s3.amazonaws.com/strata_logo.png\" class=\"ad-profile-image\"/>\r\n<img src=\"http://orm-other.s3.amazonaws.com/StrataRx_logo.png\" class=\"ad-profile-image\"/>\r\n<img src=\"http://orm-other.s3.amazonaws.com/velocity_logo.png\" class=\"ad-profile-image\"/>-->\r\n</a>\r\n</li>\r\n\r\n<li>\r\n<!--AD TEXT, 2 LINES, REPLACE LINK URL AS WELL-->\r\n<p class=\"banner-text\">Enjoy this online version of <em>Parallel and Concurrent Programming in Haskell</em>. Purchase and download the DRM-free ebook on <a href=\"http://shop.oreilly.com/product/0636920026365.do\">oreilly.com</a>.<span class=\"ebook-advantage\">Learn more about the O’Reilly <a href=\"http://shop.oreilly.com/category/ebooks.do\">Ebook Advantage</a>.</span></p>\r\n</li>\r\n\r\n<li>\r\n<!--BUY BUTTON-->\r\n<a class=\"webbutton\" href=\"http://shop.oreilly.com/product/0636920026365.do\">Buy the Ebook</a>\r\n</li> \r\n\r\n</ul>\r\n\r\n</div>\r\n\r\n<!--CORNER BANNER (IF NEEDED)-->\r\n<!--<a href=\"http://shop.oreilly.com/product/0636920026365.do\" class=\"top-banner\"><img src=\"http://orm-other.s3.amazonaws.com/banner.png\" /></a>-->\r\n\r\n</div>"}});

		/* Janrain setup */
  	var janrainModal = new JanrainView();
  	$("head").append(janrainModal.render().el);

  	/* segment.io setup */
  	var analytics=analytics||[];analytics.load=function(e){var t=document.createElement("script");t.type="text/javascript",t.async=!0,t.src=("https:"===document.location.protocol?"https://":"http://")+"d2dq2ahtl5zl1z.cloudfront.net/analytics.js/v1/"+e+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(t,n);var r=function(e){return function(){analytics.push([e].concat(Array.prototype.slice.call(arguments,0)))}},i=["identify","track","trackLink","trackForm","trackClick","trackSubmit","pageview","ab","alias","ready"];for(var s=0;s<i.length;s++)analytics[i[s]]=r(i[s])};
  	
  	analytics.load("hg9h6b9pae");

  	$(function() {
			app.bookapp = new BookApp();
		});
	
	</script>
</head>
<body>
	<div id="menu">
	
		<ul id="menu-left">
			<li id="home-link"><a href="http://chimera.labs.oreilly.com/"><i class="icon-house"></i></a></li>
			<li><a href="http://chimera.labs.oreilly.com/books/1230000000929">Parallel and Concurrent Programming in Haskell</a></li>
			<div class="clear"></div>
		</ul>
	
		<ul id="menu-right">
			<li id="comments-link"><a>&nbsp;</a></li>
			<li>
				<a href="#" class="dropdown-toggle" data-toggle="dropdown">Chapters</a>
				<div id="toc-popup" class="dropdown-menu"></div>
			</li>
				<li><a href="#" class="capture_modal_open" id="capture_signin_link">Log In / Sign Up</a></li>
			<li id="search-li">
				<form accept-charset="UTF-8" action="http://chimera.labs.oreilly.com/searches" id="search-form" method="get"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /></div>
	<input name='search[q]' type="text" placeholder="Search book..." id="book-search" />

	<input id="search_bookId" name="search[bookId]" type="hidden" value="1230000000929" />
	
	<div style='display:none'>
		sorted by: 
		<select name='search[sort]' >
			<option value='relevance'>Relevance</option>
			<option value='authors'>Author(s)</option>
			<option value='title'>Title</option>
		</select>
		returning
		<select name='search[limit]' >
			<option value='5'>5</option>
			<option value='10'>10</option>
			<option value='20'>20</option>
			<option selected="selected" value='50'>50</option>
			<option value='100'>100</option>
		</select>
		values at a time.
	</div>
</form>
			</li>
			<div class="clear"></div>
		</ul>
		<div class="clear"></div>
	
</div>
	<header><div class="navheader">
<table style="width: 100%; ">
<tr><td style="text-align: center; " colspan="3">Part I. Parallel Haskell</td></tr>
<tr>
<td style="width: 20%; text-align: left; ">
<a accesskey="p" href="ch01.html">Prev</a> </td>
<td style="width: 60%; text-align: center; "> </td>
<td style="width: 20%; text-align: right; "> <a accesskey="n" href="ch02.html">Next</a>
</td>
</tr>
</table>
<hr>
</div></header><div class="part" id="part_parallel">
<div class="titlepage"><div><div><h1 class="title">Part I. Parallel Haskell</h1></div></div></div>
<div class="partintro" id="sec_par-intro">
<div></div>
<p id="now_that_proces">Now that processor manufacturers have largely given up trying to
squeeze more performance out of individual processors and have
refocused their attention on providing us with more processors
instead, the biggest gains in performance are to be had by using
parallel techniques in our programs so as to make use of these extra
cores.  Parallel Haskell is aimed at providing access to multiple
processors in a natural and robust way.</p>
<p id="par-intro_00000000">You might wonder whether the compiler could automatically parallelize
programs for us. After all, it should be easier to do this in a purely
functional language, where the only dependencies between computations
are data dependencies, which are mostly perspicuous and thus
readily analyzed.  However, even in a purely functional language,
automatic parallelization is thwarted by an age-old problem: To make
the program faster, we have to gain more from parallelism than we lose
due to the overhead of adding it, and compile-time analysis
cannot make good judgments in this area. An alternative approach
is to use runtime profiling to find good candidates for
parallelization and to feed this information back into the compiler.
Even this, however, has not been terribly successful in practice.</p>
<p id="par-intro_00000001">Fully automatic parallelization is still a pipe dream.  However, the
parallel programming models provided by Haskell do succeed in
eliminating some mundane or error-prone aspects traditionally
associated with parallel programming:</p>
<div class="itemizedlist" id="par-intro_00000002"><ul class="itemizedlist">
<li class="listitem">
Parallel programming in Haskell is <span class="emphasis"><em>deterministic</em></span>: The parallel
program always produces the same answer, regardless of how many
processors are used to run it. So parallel programs can be debugged
without actually running them in parallel. Furthermore, the
programmer can be confident that adding parallelism will not
<span class="keep-together">introduce</span> lurking race conditions or deadlocks that would be hard to eliminate with testing.
</li>
<li class="listitem">
<p id="parallel_haskel_id1" class="simpara">
Parallel Haskell programs are high-level and declarative and do not
explicitly deal with concepts like <span class="emphasis"><em>synchronization</em></span> or
<span class="emphasis"><em>communication</em></span>.  The programmer indicates where the parallelism is,
and the details of actually running the program in parallel are left
to the runtime system.  This is both a blessing and a curse:
</p>
<div class="itemizedlist" id="par-intro_00000004"><ul class="itemizedlist">
<li class="listitem">
By embodying fewer operational details, parallel Haskell programs
are abstract and are therefore likely to work on a wide range of
parallel hardware.
</li>
<li class="listitem">
Parallel Haskell programs can take advantage of existing
highly tuned technology in the runtime system, such as parallel
garbage collection.  Furthermore, the program gets to benefit from
future improvements made to the runtime with no additional effort.
</li>
<li class="listitem">
Because a lot of the details of execution are hidden, performance
problems can be hard to understand.  Moreover, the programmer has
less control than he would in a lower-level programming
language, so fixing performance problems can be tricky.  Indeed,
this problem is not limited to Parallel Haskell: It will be
familiar to anyone who has tried to optimize Haskell programs at
all.  In this book, I hope to demonstrate how to identify and work
around the most common issues that can occur in practice.
</li>
</ul></div>
</li>
</ul></div>
<p id="par-intro_00000008">The main thing that the parallel Haskell programmer has to think about
is <span class="emphasis"><em>partitioning</em></span>: dividing up the problem into pieces that can be
computed in parallel.  Ideally, you want to have enough tasks to keep all the processors busy continuously.  However, your efforts
may be frustrated in two ways:</p>
<div class="variablelist" id="par-intro_00000009"><dl class="variablelist">
<dt><span class="term">
Granularity
</span></dt>
<dd>
If you make your tasks too small,
the overhead of managing the tasks outweighs any benefit you
might get from running them in parallel.  So granularity should
be large enough to dwarf overhead, but not too large,
because then you risk not having enough work to keep all the
processors busy, especially toward the end of the execution
when there are fewer tasks left.
</dd>
<dt><span class="term">
Data dependencies
</span></dt>
<dd>
When one task depends on another, they must be performed sequentially.
The first two programming models we will be encountering in this
book take different approaches to data dependencies: In <a class="xref" href="ch03.html" title="Chapter 3. Evaluation Strategies">Chapter 3</a>, data dependencies are entirely implicit,
whereas in <a class="xref" href="ch04.html" title="Chapter 4. Dataflow Parallelism: The Par Monad">Chapter 4</a> they are
explicit. Programming with explicit data dependencies is less concise,
but it can be easier to understand and fix problems when the data
dependencies are not hidden.
</dd>
</dl></div>
<p id="par-intro_00000011">In the following chapters, we will describe the various parallel
programming models that Haskell provides:</p>
<div class="itemizedlist" id="par-intro_00000012"><ul class="itemizedlist">
<li class="listitem">
Chapters <a class="xref" href="ch02.html" title="Chapter 2. Basic Parallelism: The Eval Monad">2</a> and <a class="xref" href="ch03.html" title="Chapter 3. Evaluation Strategies">3</a> introduce
the <code class="literal">Eval</code> monad and Evaluation Strategies, which are suitable for
expressing parallelism in Haskell programs that are not
heavily numerical or array-based.  These programming models are
well established, and there are many good examples of using them to
achieve parallelism.
</li>
<li class="listitem">
<a class="xref" href="ch04.html" title="Chapter 4. Dataflow Parallelism: The Par Monad">Chapter 4</a> introduces the <code class="literal">Par</code> monad, a more recent
parallel programming model that also aims at parallelizing ordinary
Haskell code but with a different trade-off: It affords the
programmer more control in exchange for some of the conciseness
and modularity of Strategies.
</li>
<li class="listitem">
<a class="xref" href="ch05.html" title="Chapter 5. Data Parallel Programming with Repa">Chapter 5</a> looks at the Repa library, which provides a rich
set of combinators for building parallel array computations.  You
can express a complex array algorithm as the composition
of several simpler operations, and the library automatically
optimizes the composition into a single-pass algorithm using a
technique called <span class="emphasis"><em>fusion</em></span>.  Furthermore, the implementation of the
library automatically parallelizes the operation using the
available processors.
</li>
<li class="listitem">
<a class="xref" href="ch06.html" title="Chapter 6. GPU Programming with Accelerate">Chapter 6</a> discusses programming with a graphics processing unit (GPU) using the
 Accelerate library, which offers a similar programming model to
Repa but runs the computation directly on the GPU.
</li>
</ul></div>
<p id="par-intro_00000016">Parallelizing Haskell code can be a joyful experience: Adding a small
annotation to your program can suddenly make it run several times
faster on a multicore machine.  It can also be a frustrating
experience. As we’ll see over the course of the next few chapters,
there are a number of pitfalls waiting to trap you.  Some of these are
Haskell-specific, and some are part and parcel of parallel programming
in any language.  Hopefully by the end you’ll have built up enough of
an intuition for parallel programming that you’ll be able to achieve
decent parallel speedups in your own code using the techniques
covered.</p>
<p id="par-intro_00000017">Keep in mind while reading this part of the book that obtaining reliable
results with parallelism is inherently difficult because in today’s
complex computing devices, performance depends on a vast number of
interacting components.  For this reason, the results I get from
running the examples on my computers might differ
somewhat from the results you get on your hardware.  Hopefully the
difference isn’t huge—if it is, that might indicate a problem in GHC
that you should report.  The important thing is to be aware that
performance is fragile, especially where parallelism is concerned.</p>
</div>
</div>
<footer><div class="navfooter">
<hr>
<table style="width: 100%; ">
<tr>
<td style="width: 40%; text-align: left; ">
<a accesskey="p" href="ch01.html">Prev</a> </td>
<td style="width: 20%; text-align: center; "> </td>
<td style="width: 40%; text-align: right; "> <a accesskey="n" href="ch02.html">Next</a>
</td>
</tr>
<tr>
<td style="width: 40%; text-align: left; vertical-align: top; ">Chapter 1. Introduction </td>
<td style="width: 20%; text-align: center; "><a accesskey="h" href="index.html">Home</a></td>
<td style="width: 40%; text-align: right; vertical-align: top; "> Chapter 2. Basic Parallelism: The Eval Monad</td>
</tr>
</table>
</div></footer>


	<div class="extra-footer">
		<p>© 2013, O’Reilly Media, Inc.</p>
		<ul>
			<li><a href="http://oreilly.com/terms/">Terms of Service</a></li>
			<li><a href="http://oreilly.com/oreilly/privacy.csp">Privacy Policy</a></li>
			<li>Interested in <a href="mailto:scordesse@oreilly.com">sponsoring content?</a></li>
		</ul>
	</div>
<script type="text/javascript">if (!NREUMQ.f) { NREUMQ.f=function() {
NREUMQ.push(["load",new Date().getTime()]);
var e=document.createElement("script");
e.type="text/javascript";
e.src=(("http:"===document.location.protocol)?"http:":"https:") + "//" +
  "js-agent.newrelic.com/nr-100.js";
document.body.appendChild(e);
if(NREUMQ.a)NREUMQ.a();
};
NREUMQ.a=window.onload;window.onload=NREUMQ.f;
};
NREUMQ.push(["nrfj","bam.nr-data.net","3e361aebcf","2194180","IApbRUBZXg1WEEoHDAwORh5aQl8N",37,29,new Date().getTime(),"","","","",""]);</script></body>

<!-- Mirrored from chimera.labs.oreilly.com/books/1230000000929/pt01.html by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 19 Dec 2016 05:52:17 GMT -->
</html>