<!doctype html>
<html lang="en">

<!-- Mirrored from ogldev.atspace.co.uk/www/tutorial49/tutorial49.html by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 26 Dec 2016 21:36:47 GMT -->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title> Tutorial 49 - Cascaded Shadow Mapping </title>

    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:400,600">
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../print.css" media="print">
</head>
<body>
    <header id="header">
        <div>
            <h2> Tutorial 49: </h2>
            <h1> Cascaded Shadow Mapping </h1>
        </div>

        <a id="logo" class="small" href="../../index-2.html" title="Homepage">
            <img src="http://ogldev.atspace.co.uk/www//logo ldpi.png">
        </a>
    </header>

<article id="content" class="breakpoint">
<section>
            <h3> Background </h3>
<p>
    Let's take a close up look of the shadow from <a href="../tutorial47/tutorial47.html">tutorial 47</a>:
</p>
<img src="http://ogldev.atspace.co.uk/www/tutorial49/img1.jpg">
<p>
    As you can see, the qaulity of the shadow is not high. It's too blocky. We've touched on the reason for that
    blockiness at the end of tutorial 47 and referred to it as <i>Perspective Aliasing</i> which
    means a large number of pixels in view space being mapped to the same pixel in the shadow map. This means
    that all these pixels will either be in shadow or in light, contributing to the sense of blockiness. 
    In other words, since the resolution of the shadow map is not high enough it cannot cover the view space
    adequately. One obvious way to deal with this is to increase the resolution of the shadow map but
    that will increase the memory footprint of our app so it may not be the best course of action.      
</p>
<p>
    Another way to deal with this problem is to notice that shadows closer to the camera a far more important
    in terms of quality than shadow of objects that are far away. Distant objects are smaller anyway and
    usually the eye focuses on what happens close by, leaving the rest as a "background". If we can find a way
    to use a dedicated shadow map for closer objects and a different shadow map for distant objects then the
    first shadow map will only need to cover the a smaller region, thus decreasing the ratio that we discusses above.
    This, in a nutshell, is what Cascaded Shadow Mapping (a.k.a CSM) is all about. At the time of writing this tutorial
    CSM is considered one of the best ways to deal with Perspective Aliasing. Let's see how we can implement it.      
</p>
<p>
    From a high level view we are going to split the view frustum into several cascades (since it doesn't need
    to be just two as in the previous example). For the purpose of this tutorial we will use three cascades: near, middle and
    far. The algorithm itself is pretty generic so you can use more cascades if you feel like it. Every cascade will
    be rendered into its own private shadow map. The shadow algorithm itself will remain the same but when sampling
    the depth from the shadow map we will need to select the appropriate map based on the distance from the viewer.
    Let's take a look at a generic view frustum:
</p>
<img src="http://ogldev.atspace.co.uk/www/tutorial49/img2.png">
<p>
    As usual, we have a small near plane and a larger far plane. Now let's take a look at the same fustum from above:
</p>
<img src="http://ogldev.atspace.co.uk/www/tutorial49/img3.png">
<p>
    The next step is to split the range from the near plane to the far plane into three parts. We will call this near, middle and far.
    In addition, let's add the light direction (the arrow on the right hand side):
</p>
<img src="http://ogldev.atspace.co.uk/www/tutorial49/img4.png">
<p>
    So how are we going to render each cascade into its own private shadow map? Let's think about the shadow
    phase in the shadow mapping algorithm. We set up things to render the scene from the light point of view. This
    means creating a WVP matrix with the world transform of the object, the view transform based on the light and
    a projection matrix. Since this tutorial is based on tutorial 47 which dealt with shadows of directional lights
    the projection matrix will be orthographic. In general CSMs make more sense in outdoor scenes where the
    main light source is usually the sun so using a directional light here is natural. If you look at the 
    WVP matrix above you will notice that the first two parts (world and view) are the same for all cascades.
    After all, the position of the object in the world and the orientation of the camera based on the light source
    are not related to the splitting of the frustum into cascades. What matters here is only the projection matrix
    because it defines the extent of the region which will eventually be rendered. And since orthographic
    projections are defined using a box we need to define three different boxes which will be translated into 
    three different orthographic projection matrices. These projection matrices will be used to create the three
    WVP matrices to render each cascade into its own shadow map.   
</p>
<p>
    The most logical thing to do will be to make these boxes as small as posible in order to keep the ratio
    of view pixels to shadow map pixels as low as possible. This means creating a bounding box for each cascade
    which is oriented along the light direction vector. Let's create such a bounding box for the first cascade:
</p>
<img src="http://ogldev.atspace.co.uk/www/tutorial49/img5.png">
<p>
    Now let's create a bounding box for the second cascade:
    </p>
<img src="http://ogldev.atspace.co.uk/www/tutorial49/img6.png">    
<p>
    And finally a bouding box for the last cascade:
    </p>
<img src="http://ogldev.atspace.co.uk/www/tutorial49/img7.png">    
<p>
    As you can see, there is some overlap of the bounding boxes due to the orientationn of the light which 
    means some pixels will be rendered into more than one shadow map. There is no problem with that
    as long as all the pixels of a single cascade are entirely inside a single shadow map. The selection of 
    the shadow map to use in the shader for shadow calculations will be based on the distance of the pixel from 
    the actual viewer. 
</p>
<p>
    Calculations of the bounding boxes that serve as the basis for the orthographic projection in the
    shadow phase is the most complicated part of the algorithm. These boxes must be described in light space
    because the projections come after world and view transforms (at which point the light "originates" from
    the origin and points along the positive Z axis). Since the boxes will be calculated as min/max values 
    on all three axis they will be aligned on the light direction, which is what we need for projection. To calculate
    the bounding box we need to know how each cascade looks like in light space. To do that we need to follow these
    steps:
    <ol>
        <li>Calculate the eight corners of each cascade in view space. This is easy and requires simple trigonometry:</li>
        <br>
          <img src="http://ogldev.atspace.co.uk/www/tutorial49/frustum1.png">
        </li> 
        <p>
            The above image represents an arbitrary cascade (since each cascade on its own is basically a frustum and
            shares the same field-of-view angle with the other cascades). Note that we are looking from the top 
            down to the XZ plane. We need to calculate X<sub>1</sub> and
            X<sub>2</sub>:             
            </p>
            <img src="http://ogldev.atspace.co.uk/www/tutorial49/calc1.png">
            <img src="http://ogldev.atspace.co.uk/www/tutorial49/calc2.png">
            <p>
                This gives us the X and Z components of the eight coordinates of the cascade in view space. Using
                similar math with the vertical field-of-view angle we can get the Y component and finalize the coordinates.
        <li>Now we need to transform the cascade coordinates from view space back to world space. Let's say that the
            viewer is oriented such that in world space the frustum looks like that (the red arrow is the light direction
            but ignore it for now):</li>
            <br>
        </li>
        <img src="http://ogldev.atspace.co.uk/www/tutorial49/frustum2.png">
        <p>
            In order to transform from world space to view space we multiply the world position vector by
            the view matrix (which is based on the camera location and rotation). This means that if we already
            have the coordinates of the cascade in view space we must multiply them by the inverse of the view matrix
            in order to transform them to world space:
            </p>        
    <img src="http://ogldev.atspace.co.uk/www/tutorial49/calc3.png">         
    <li>
        With the frustum coordinates in world space we can now transform them to light space as any other object.
        Remember that the light space is exactly like view space but instead of the camera we use the light source. 
        Since we are dealing with a directional light that has no origin we just need to rotate the world so that
        the light direction becomes aligned with the positive Z axis. The origin of light can simply be the origin
        of the light space coordinate system (which means we don't need any translation). If we do that using the previous
        diagram (with the red arrow being the light direction) the cascade frustum in light space should look like: 
        </li>   
        <br>
        <img src="http://ogldev.atspace.co.uk/www/tutorial49/frustum3.png">
        <li>
            With the cascade coordinates finally in light space we just need to generate a bounding box for it
            by taking the min/max values of the X/Y/Z components of the eight coordinates. This bounding box 
            provides the values for the orthographic projection for rendering this cascade into its shadow map.
            By generating an orthographic projection for each cascade separately we can now render each cascade
            into different shadow map. During the light phase we will calculate the shadow factor by selecting
            a shadow map based on the distance from the viewer. 
            </li>
        </ol>    
</p>
</section>

<section>
<h3> Source walkthru </h3>
<p>(ogldev_shadow_map_fbo.cpp:104)</p>

<code>
bool CascadedShadowMapFBO::Init(unsigned int WindowWidth, unsigned int WindowHeight)<br>
{<br>
&nbsp; &nbsp;     // Create the FBO<br>
&nbsp; &nbsp;     glGenFramebuffers(1, &m_fbo);<br>
<br>
&nbsp; &nbsp;     // Create the depth buffer    <br>
&nbsp; &nbsp;     glGenTextures(ARRAY_SIZE_IN_ELEMENTS(m_shadowMap), m_shadowMap);<br>
    <br>
&nbsp; &nbsp;     for (uint i = 0 ; i < ARRAY_SIZE_IN_ELEMENTS(m_shadowMap) ; i++) {<br>
&nbsp; &nbsp; &nbsp; &nbsp;         glBindTexture(GL_TEXTURE_2D, m_shadowMap[i]);<br>
&nbsp; &nbsp; &nbsp; &nbsp;         glTexImage2D(GL_TEXTURE_2D, 0, GL_DEPTH_COMPONENT32, WindowWidth, WindowHeight, 0, GL_DEPTH_COMPONENT, GL_FLOAT, NULL);<br>
&nbsp; &nbsp; &nbsp; &nbsp;         glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);<br>
&nbsp; &nbsp; &nbsp; &nbsp;         glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);<br>
&nbsp; &nbsp; &nbsp; &nbsp;         glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_COMPARE_MODE, GL_NONE);<br>
&nbsp; &nbsp; &nbsp; &nbsp;         glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br>
&nbsp; &nbsp; &nbsp; &nbsp;         glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br>
&nbsp; &nbsp;     }<br>
<br>
&nbsp; &nbsp;     glBindFramebuffer(GL_FRAMEBUFFER, m_fbo);<br>
&nbsp; &nbsp;     glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, m_shadowMap[0], 0);<br>
<br>
&nbsp; &nbsp;     // Disable writes to the color buffer<br>
&nbsp; &nbsp;     glDrawBuffer(GL_NONE);<br>
&nbsp; &nbsp;     glReadBuffer(GL_NONE);<br>
<br>
&nbsp; &nbsp;     GLenum Status = glCheckFramebufferStatus(GL_FRAMEBUFFER);<br>
<br>
&nbsp; &nbsp;     if (Status != GL_FRAMEBUFFER_COMPLETE) {<br>
&nbsp; &nbsp;         printf("FB error, status: 0x%x\n", Status);<br>
&nbsp; &nbsp;         return false;<br>
&nbsp; &nbsp;     }<br>
<br>
&nbsp; &nbsp;     return true;<br>
}<br>
<br>
<br>
void CascadedShadowMapFBO::BindForWriting(uint CascadeIndex)<br>
{<br>
&nbsp; &nbsp;     assert(CascadeIndex < ARRAY_SIZE_IN_ELEMENTS(m_shadowMap));<br>
&nbsp; &nbsp;     glBindFramebuffer(GL_DRAW_FRAMEBUFFER, m_fbo);<br>
&nbsp; &nbsp;     glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, m_shadowMap[CascadeIndex], 0);<br>    
}<br>
<br>
<br>
void CascadedShadowMapFBO::BindForReading()<br>
{<br>
&nbsp; &nbsp;     glActiveTexture(CASCACDE_SHADOW_TEXTURE_UNIT0);<br>
&nbsp; &nbsp;     glBindTexture(GL_TEXTURE_2D, m_shadowMap[0]);<br>
<br>
&nbsp; &nbsp;     glActiveTexture(CASCACDE_SHADOW_TEXTURE_UNIT1);<br>
&nbsp; &nbsp;     glBindTexture(GL_TEXTURE_2D, m_shadowMap[1]);<br>
<br>
&nbsp; &nbsp;     glActiveTexture(CASCACDE_SHADOW_TEXTURE_UNIT2);<br>
&nbsp; &nbsp;     glBindTexture(GL_TEXTURE_2D, m_shadowMap[2]);<br>
}<br>
</code>
<p>
    The CascadedShadowMapFBO class we see above is a modification of the ShadowMapFBO class
    that we have previously used for shadow mapping. The main change is that the m_shadowMap
    array has space for three shadow map objects which is the number of cascades we are going
    to use for this example. Here we have the three main functions of the class used to
    initialize it, bind it for writing in the shadow map phase and for reading in the lighting phase.
    </p>

<p>(tutorial49.cpp:197)</p>
<code>    
    virtual void RenderSceneCB()<br>
    {   <br>
&nbsp; &nbsp;        for (int i = 0; i < NUM_MESHES ; i++) {<br>
&nbsp; &nbsp; &nbsp; &nbsp;             m_meshOrientation[i].m_rotation.y += 0.5f;<br>
&nbsp; &nbsp;         }<br>
        <br>
&nbsp; &nbsp;         m_pGameCamera->OnRender();<br>
        <br>
&nbsp; &nbsp;         ShadowMapPass();<br>
&nbsp; &nbsp;         RenderPass();<br>
&nbsp; &nbsp;         OgldevBackendSwapBuffers();<br>
    }
</code>    
<p>
    The main render function in the CCM algorithm is the same as in the standard shadow mapping algorithm - first
    render into the shadow maps and then use them for the actual lighting.
    </p>
<p>(tutorial49.cpp:211)</p>    
<code>   
    void ShadowMapPass()<br>
    {      <br>
&nbsp; &nbsp;         <b>CalcOrthoProjs();</b><br>
<br>
&nbsp; &nbsp;         m_ShadowMapEffect.Enable();<br>
<br>               
&nbsp; &nbsp;         Pipeline p;<br>
                <br>
&nbsp; &nbsp;                 // The camera is set as the light source - doesn't change in this phase<br>
&nbsp; &nbsp;         p.SetCamera(Vector3f(0.0f, 0.0f, 0.0f), m_dirLight.Direction, Vector3f(0.0f, 1.0f, 0.0f));<br>
               <br>
&nbsp; &nbsp;         for (uint i = 0 ; i < NUM_CASCADES ; i++) {<br>
&nbsp; &nbsp; &nbsp; &nbsp;             // Bind and clear the current cascade<br>
&nbsp; &nbsp; &nbsp; &nbsp;            <b> m_csmFBO.BindForWriting(i);</b><br>
&nbsp; &nbsp; &nbsp; &nbsp;             glClear(GL_DEPTH_BUFFER_BIT);  <br>          
                        <br>
&nbsp; &nbsp; &nbsp; &nbsp;           <b>  p.SetOrthographicProj(m_shadowOrthoProjInfo[i]);</b><br>                    
<br>
&nbsp; &nbsp; &nbsp; &nbsp;             for (int i = 0; i < NUM_MESHES ; i++) {<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 p.Orient(m_meshOrientation[i]);<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 m_ShadowMapEffect.SetWVP(p.GetWVOrthoPTrans());<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 m_mesh.Render();<br>
&nbsp; &nbsp;             &nbsp; &nbsp; }<br>
&nbsp; &nbsp;         }<br>
        <br>
&nbsp; &nbsp;         glBindFramebuffer(GL_FRAMEBUFFER, 0);<br>
    }
</code> 
<p>
    There are a few changes in the shadow mapping phase worth noting. The first is the call to CalOrthoProjs()
    at the start of the phase. This function is responsible for calculating the bounding boxes used for
    orthographic projections. The next change is the loop over the cascades. Each cascade must be bound for writing, 
    cleared and rendered to separately. Each cascade has its own projection set up in the m_shadowOrthoProjInfo array (done by
    CalcOrthoProjs). Since we don't know which mesh goes to which cascade (and it can be more than one) we have
    to render the entire scene into all the cascades.
</p>   
<p>(tutorial49.cpp:238)</p>
<code>
    void RenderPass()<br>
    {<br>
&nbsp; &nbsp;         glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);<br>
<br>
&nbsp; &nbsp;         m_LightingTech.Enable();<br>
<br>
&nbsp; &nbsp;         m_LightingTech.SetEyeWorldPos(m_pGameCamera->GetPos());<br>
       <br>
&nbsp; &nbsp;         m_csmFBO.BindForReading();<br>
<br>
&nbsp; &nbsp;         Pipeline p;<br>        
&nbsp; &nbsp;         p.Orient(m_quad.GetOrientation());<br>                
&nbsp; &nbsp;         p.SetCamera(Vector3f(0.0f, 0.0f, 0.0f), m_dirLight.Direction, Vector3f(0.0f, 1.0f, 0.0f));<br>
<br>
&nbsp; &nbsp;   <b>      for (uint i = 0 ; i < NUM_CASCADES ; i++) {<br>
&nbsp; &nbsp; &nbsp; &nbsp;             p.SetOrthographicProj(m_shadowOrthoProjInfo[i]);<br>        
&nbsp; &nbsp; &nbsp; &nbsp;             m_LightingTech.SetLightWVP(i, p.GetWVOrthoPTrans());<br>
&nbsp; &nbsp;         }</b><br>
                <br>
&nbsp; &nbsp;         p.SetCamera(m_pGameCamera->GetPos(), m_pGameCamera->GetTarget(), m_pGameCamera->GetUp());<br>
&nbsp; &nbsp;         p.SetPerspectiveProj(m_persProjInfo);                <br>
&nbsp; &nbsp;         m_LightingTech.SetWVP(p.GetWVPTrans());<br>
&nbsp; &nbsp;         m_LightingTech.SetWorldMatrix(p.GetWorldTrans());<br>        
&nbsp; &nbsp;         m_pGroundTex->Bind(COLOR_TEXTURE_UNIT);<br>
<br>
&nbsp; &nbsp;         m_quad.Render();<br>
           <br>
&nbsp; &nbsp;         for (int i = 0; i < NUM_MESHES ; i++) {<br>
&nbsp; &nbsp; &nbsp; &nbsp;             p.Orient(m_meshOrientation[i]);        <br>             
&nbsp; &nbsp; &nbsp; &nbsp;             m_LightingTech.SetWVP(p.GetWVPTrans());<br>
&nbsp; &nbsp; &nbsp; &nbsp;             m_LightingTech.SetWorldMatrix(p.GetWorldTrans());<br>
&nbsp; &nbsp; &nbsp; &nbsp;             m_mesh.Render();<br>
&nbsp; &nbsp;         }<br>
    }    
    </code>
 <p>
     The only change in the lighting phase is that instead of a single light WVP matrix we have three.
     They are identical except for the projection part. We set them up accordingly in the loop at the middle
     of the phase.
     </p> 
<p>(tutorial49.cpp:80)</p>     
<code>
&nbsp; &nbsp;         m_cascadeEnd[0] = m_persProjInfo.zNear;<br>
&nbsp; &nbsp;         m_cascadeEnd[1] = 25.0f,<br>
&nbsp; &nbsp;         m_cascadeEnd[2] = 90.0f,<br>
&nbsp; &nbsp;         m_cascadeEnd[3] = m_persProjInfo.zFar;<br>    
    </code>     
    <p>
Before we study how to calculate the orthographic projections we need to take a look
at the m_cascadeEnd array (which is set up as part of the constructor). This array defines the 
cascades by placing the near Z and far Z in the first and last slots, respectively, and the ends of
the cascades in between. So the first cascade ends in the value of slot one, the second in slot two
and the last cascade ends with the far Z in the last slot. We need the near Z in the first slot to simplify
the calculations later.
</p>
<p>(tutorial49.cpp:317)</p>
<code>
    void CalcOrthoProjs()<br>
    {                        <br>           
&nbsp; &nbsp;         Pipeline p;<br>
        <br>
&nbsp; &nbsp;         // Get the inverse of the view transform<br>        
&nbsp; &nbsp;         p.SetCamera(m_pGameCamera->GetPos(), m_pGameCamera->GetTarget(), m_pGameCamera->GetUp());<br>
&nbsp; &nbsp;         Matrix4f Cam = p.GetViewTrans();<br>
&nbsp; &nbsp;         Matrix4f CamInv = Cam.Inverse();<br>
        <br>
&nbsp; &nbsp;         // Get the light space tranform<br> 
&nbsp; &nbsp;         p.SetCamera(Vector3f(0.0f, 0.0f, 0.0f), m_dirLight.Direction, Vector3f(0.0f, 1.0f, 0.0f));<br>
&nbsp; &nbsp;         Matrix4f LightM = p.GetViewTrans();<br>
        <br>
&nbsp; &nbsp;         float ar = m_persProjInfo.Height / m_persProjInfo.Width;<br>
&nbsp; &nbsp;         float tanHalfHFOV = tanf(ToRadian(m_persProjInfo.FOV / 2.0f));<br>
&nbsp; &nbsp;         float tanHalfVFOV = tanf(ToRadian((m_persProjInfo.FOV * ar) / 2.0f));<br>
                        <br>
&nbsp; &nbsp;         for (uint i = 0 ; i < NUM_CASCADES ; i++) {<br>
&nbsp; &nbsp; &nbsp; &nbsp;             float xn = m_cascadeEnd[i]     * tanHalfHFOV;<br>
&nbsp; &nbsp; &nbsp; &nbsp;             float xf = m_cascadeEnd[i + 1] * tanHalfHFOV;<br>
&nbsp; &nbsp; &nbsp; &nbsp;             float yn = m_cascadeEnd[i]     * tanHalfVFOV;<br>
&nbsp; &nbsp; &nbsp; &nbsp;             float yf = m_cascadeEnd[i + 1] * tanHalfVFOV;<br>
<br>
&nbsp; &nbsp; &nbsp; &nbsp;             Vector4f frustumCorners[NUM_FRUSTUM_CORNERS] = {<br> 
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 // near face<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 Vector4f(xn,   yn, m_cascadeEnd[i], 1.0),<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 Vector4f(-xn,  yn, m_cascadeEnd[i], 1.0),<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 Vector4f(xn,  -yn, m_cascadeEnd[i], 1.0),<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 Vector4f(-xn, -yn, m_cascadeEnd[i], 1.0),<br>
                <br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 // far face<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 Vector4f(xf,   yf, m_cascadeEnd[i + 1], 1.0),<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 Vector4f(-xf,  yf, m_cascadeEnd[i + 1], 1.0),<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 Vector4f(xf,  -yf, m_cascadeEnd[i + 1], 1.0),<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 Vector4f(-xf, -yf, m_cascadeEnd[i + 1], 1.0)     <br>       
&nbsp; &nbsp; &nbsp; &nbsp;             };<br>
</code>
<p>
    What we see above matches step #1 of the description in the background section on how to 
    calculate the orthographic projections for the cascades. The frustumCorners array is populated with
    the eight corners of each cascade in view space. Note that since the field of view is provided only
    for the horizontal axis we have to extrapolate it for the vertical axis (e.g, if the horizontal field of
    view is 90 degrees and the window has a width of 1000 and a height of 500 the vertical field of view
    will be only 45 degrees). 
    </p>
<code>    
&nbsp; &nbsp; &nbsp; &nbsp;             Vector4f frustumCornersL[NUM_FRUSTUM_CORNERS];<br>
<br>
&nbsp; &nbsp; &nbsp; &nbsp;             float minX = std::numeric_limits<float>::max();<br>
&nbsp; &nbsp; &nbsp; &nbsp;             float maxX = std::numeric_limits<float>::min();<br>
&nbsp; &nbsp; &nbsp; &nbsp;             float minY = std::numeric_limits<float>::max();<br>
&nbsp; &nbsp; &nbsp; &nbsp;             float maxY = std::numeric_limits<float>::min();<br>
&nbsp; &nbsp; &nbsp; &nbsp;             float minZ = std::numeric_limits<float>::max();<br>
&nbsp; &nbsp; &nbsp; &nbsp;             float maxZ = std::numeric_limits<float>::min();<br>
<br>
&nbsp; &nbsp; &nbsp; &nbsp;             for (uint j = 0 ; j < NUM_FRUSTUM_CORNERS ; j++) {<br><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 // Transform the frustum coordinate from view to world space<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 Vector4f vW = CamInv * frustumCorners[j];<br><br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 // Transform the frustum coordinate from world to light space<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 frustumCornersL[j] = LightM * vW;<br>
<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                  minX = min(minX, frustumCornersL[j].x);<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 maxX = max(maxX, frustumCornersL[j].x);<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 minY = min(minY, frustumCornersL[j].y);<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 maxY = max(maxY, frustumCornersL[j].y);<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 minZ = min(minZ, frustumCornersL[j].z);<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;                 maxZ = max(maxZ, frustumCornersL[j].z);<br>
&nbsp; &nbsp; &nbsp; &nbsp;            }<br>           
</code>          
<p>
    The above code contains step #2 until #4. Each frustum corner coordinate is multiplied
    by the inverse view transform in order to bring it into world  space. It is then
    multiplied by the light transform in order to move it into light space. We then use
    a series of min/max functions in order to find the size of the bounding box of the cascade in 
    light space.
    </p>  
    <code>           
&nbsp; &nbsp; &nbsp; &nbsp;             m_shadowOrthoProjInfo[i].r = maxX;<br>
&nbsp; &nbsp; &nbsp; &nbsp;             m_shadowOrthoProjInfo[i].l = minX;<br>
&nbsp; &nbsp; &nbsp; &nbsp;             m_shadowOrthoProjInfo[i].b = minY;<br>
&nbsp; &nbsp; &nbsp; &nbsp;             m_shadowOrthoProjInfo[i].t = maxY;<br>
&nbsp; &nbsp; &nbsp; &nbsp;             m_shadowOrthoProjInfo[i].f = maxZ;<br>
&nbsp; &nbsp; &nbsp; &nbsp;             m_shadowOrthoProjInfo[i].n = minZ;<br>
&nbsp; &nbsp; 		}<br>
	}
</code>    
<p>
    The current entry in the m_shadowOrthoProjInfo array is populated using the values 
    of the bounding box.
    </p>
    <p>(csm.vs)</p>
<code>
#version 330   <br>                                                                     
                   <br>                                                                 
layout (location = 0) in vec3 Position;                                             <br>
layout (location = 1) in vec2 TexCoord;<br>                                             
layout (location = 2) in vec3 Normal;      <br>                                         
                                               <br>                                     
uniform mat4 gWVP;                                 <br>                                 
                                                       <br>                                                                                                                
void main()                                                <br>                         
{                                                              <br>                     
&nbsp; &nbsp;     gl_Position = gWVP * vec4(Position, 1.0);<br>
}
</code>
<p>(csm.fs)</p>
<code>
#version 330<br>                                                                                                                                                                                                                                          
                <br>                                                                    
void main()         <br>                                                                
{                       <br>                                                            
}
 </code>
 <p>
     There is nothing new in the vertex and fragment shaders of the shadow map phase. We just need to
     render the depth.
     </p>
<p>(lighting.vs)</p>      
<code>
#version 330<br>
<br>
layout (location = 0) in vec3 Position;<br>
layout (location = 1) in vec2 TexCoord;<br>
layout (location = 2) in vec3 Normal;<br>
<br>
<b>const int NUM_CASCADES = 3;</b><br>
<br>
uniform mat4 gWVP;<br>
uniform mat4 gLightWVP<b>[NUM_CASCADES];</b><br>
uniform mat4 gWorld;<br>
<br>
out vec4 LightSpacePos<b>[NUM_CASCADES];</b><br>
<b>out float ClipSpacePosZ;</b><br>
out vec2 TexCoord0;<br>
out vec3 Normal0;<br>
out vec3 WorldPos0;<br>
<br>
void main()<br>
{<br>
&nbsp; &nbsp;     vec4 Pos = vec4(Position, 1.0);<br>
<br>
&nbsp; &nbsp;     gl_Position = gWVP * Pos;<br>
    <br>
&nbsp; &nbsp;    <b> for (int i = 0 ; i < NUM_CASCADES ; i++) {<br>
&nbsp; &nbsp; &nbsp; &nbsp;         LightSpacePos[i] = gLightWVP[i] * Pos;<br>
&nbsp; &nbsp;     }<br>
<br>
&nbsp; &nbsp;     ClipSpacePosZ = gl_Position.z;</b><br>
&nbsp; &nbsp;     TexCoord0     = TexCoord;<br>
&nbsp; &nbsp;     Normal0       = (gWorld * vec4(Normal, 0.0)).xyz;<br>
&nbsp; &nbsp;     WorldPos0     = (gWorld * vec4(Position, 1.0)).xyz;<br>
}
</code>    
<p>
    Let's review the changes in the vertex shader of the lighting phase. Instead
    of a single position in light space we are going to output one for each cascade
    and select the proper one for each pixel in the fragment shader. You can optimize this 
    later but for educational purposes I found this to be the simplest way to go. Remember
    that you cannot select the cascade in the vertex shader anyway because a triangle 
    can be cross cascade. So we have three light space WVP matrices and we output
    three light space positions. In addition, we also output the Z component of
    the clip space coordinate. We will use this in the fragment shader to select 
    the cascade. Note that this is calculated in view space and not light space.   
    </p>
<p>(lighting.fs)</p>         
<code>
const int NUM_CASCADES = 3;<br>
<br>
in vec4 LightSpacePos[NUM_CASCADES];<br>
in float ClipSpacePosZ;<br>
<br>
uniform sampler2D gShadowMap[NUM_CASCADES];<br>
uniform float gCascadeEndClipSpace[NUM_CASCADES];<br>    
</code>
<p>
    The fragment shader of the lighting phase requires some changes/additions in
    the general section. We get the three light space positions calculated by
    the vertex shader as input as well as the Z component of the clip space coordinate.
    Instead of a single shadow map we now have three. In addition, the application must supply
    the end of each cascade in clip space. We will see later how to calculate this. For now
    just assume that it is available.
</p>
<code>
float CalcShadowFactor(<b>int CascadeIndex,</b> vec4 LightSpacePos)<br>                                                  
{                                                               <br>                            
&nbsp; &nbsp;     vec3 ProjCoords = LightSpacePos.xyz / LightSpacePos.w;          <br>
<br>                        
&nbsp; &nbsp;     vec2 UVCoords;                                                      <br>                    
&nbsp; &nbsp;     UVCoords.x = 0.5 * ProjCoords.x + 0.5;                                  <br>                
&nbsp; &nbsp;     UVCoords.y = 0.5 * ProjCoords.y + 0.5;                                      <br>
<br>            
&nbsp; &nbsp;     float z = 0.5 * ProjCoords.z + 0.5;                                             <br>        
&nbsp; &nbsp;     float Depth = texture(gShadowMap<b>[CascadeIndex]</b>, UVCoords).x;                        <br>
<br>                  
&nbsp; &nbsp;     if (Depth < z + 0.00001)                                                                <br> 
&nbsp; &nbsp; &nbsp; &nbsp;         return 0.5;<br>                                                                         
&nbsp; &nbsp;     else               <br>                                                                     
&nbsp; &nbsp; &nbsp; &nbsp;         return 1.0;        <br>                                                                 
}                              <br>                                                             
    <br>
void main()<br>                                                                        
{              <br>                                                                                 
&nbsp; &nbsp;     float ShadowFactor = 0.0;<br>
<br>
&nbsp; &nbsp;     for (int i = 0 ; i < NUM_CASCADES ; i++) {<br>
&nbsp; &nbsp; &nbsp; &nbsp;         if (ClipSpacePosZ <= gCascadeEndClipSpace[i]) {<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;             ShadowFactor = CalcShadowFactor(i, LightSpacePos[i]);<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;             break;<br>
&nbsp; &nbsp; &nbsp; &nbsp;         }<br>
&nbsp; &nbsp;    }<br>
&nbsp; &nbsp;    ...    
</code>    
<p>
    In order to find out the proper cascade for the current pixel
    we traverse the uniform gCascadeEndClipSpace array and compare the Z component of the
    clip space coordinate to each entry. The array is sorted from the closest cascade to
    the furthest. We stop as soon as we find an entry whose value is greater than or equal 
    to that Z component. We then call the CalcShadowFactor() function and pass in the index of the
    cascade we found. The only change to CalcShadowFactor() is that it samples the depth from the
    shadow map which matches that index. Everything else is the same.
    </p>
<p>(tutorial49.cpp:134)</p>    
<code>
        for (uint i = 0 ; i < NUM_CASCADES ; i++) {<br>
&nbsp; &nbsp;             Matrix4f Proj;<br>
&nbsp; &nbsp;             Proj.InitPersProjTransform(m_persProjInfo);<br>
&nbsp; &nbsp;             Vector4f vView(0.0f, 0.0f, m_cascadeEnd[i + 1], 1.0f);<br>
&nbsp; &nbsp;             Vector4f vClip = Proj * vView;<br>
&nbsp; &nbsp;             m_LightingTech.SetCascadeEndClipSpace(i, vClip.z);<br>
        }    
</code>       
<p>
    The last piece of the puzzle is to prepare the values for the gCascadeEndClipSpace array. 
    For this we simply take the (0, 0, Z) coordinate where Z is the end of the cascade in view space.
    We project it using our standard perspective projection transform to move it into clip space. 
    We do this for each cascade in order to calculate the end of every cascade in clip space. 
    </p>
<p>
    If you study the tutorial sample code you will see that I've added a cascade indicator
    by adding a red, green or blue color to each cascade to make them stand out. This is
    very useful for debugging because you can actually see the extent of each cascade. 
    With the CSM algorithm (and the cascade indicator) the scene should now look like this:
    </p>    
<img src="http://ogldev.atspace.co.uk/www/tutorial49/final.jpg">
</section>
</article>    
    
</section>
        <a href="../tutorial50/tutorial50.html" class="next highlight"> Next tutorial </a>
</article>    
    

<script src="../html5shiv.min.html"></script>
<script src="../html5shiv-printshiv.min.html"></script>

<div id="disqus_thread"></div>
<script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = 'ogldevatspacecouk'; // required: replace example with your forum shortname
var disqus_url = 'http://www.ogldev.org/www/tutorial47/tutorial47.html'

/* * * DON'T EDIT BELOW THIS LINE * * */
(function() {
var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</body>

<!-- Mirrored from ogldev.atspace.co.uk/www/tutorial49/tutorial49.html by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 26 Dec 2016 21:36:47 GMT -->
</html>
