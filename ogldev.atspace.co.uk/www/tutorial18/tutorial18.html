<!doctype html>
<html lang="en">

Providence Salumu
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">

	<title> Tutorial 18 - Diffuse Lighting </title>

	<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:400,600">
	<link rel="stylesheet" href="../style.css">
	<link rel="stylesheet" href="../print.css" media="print">
</head>
<body>
	<header id="header">
		<div>
			<h2> Tutorial 18: </h2>
			<h1> Diffuse Lighting </h1>
		</div>

		<a id="logo" class="small" href="../../index-2.html" title="Homepage">
			<img src="http://ogldev.atspace.co.uk/www//logo ldpi.png">
		</a>
	</header>

	<article id="content" class="breakpoint">
		<section>
			<h3> Background </h3>

			<p>
				The main difference between ambient light and diffuse light is the fact that diffuse light is dependent on
				the direction of the rays of light while ambient light ignores it completely. When only ambient light is present the
				entire scene is equally lit. Diffuse light makes the parts of objects that face the light brighter than the parts
				that are opposite from it.
			</p>
			<p>
				Diffuse light also adds a twist where the angle by which the light strikes the surface determines the brightness
				of that surface. This concept is demonstrated by the following picture:
			</p>
			<img class="center" src="http://ogldev.atspace.co.uk/www/tutorial18/light_angle.png">
			<p>
				Let's assume that the strength of both light rays is the same and the only difference is their direction. The model
				of diffuse light says that the surface on the left will be brighter than the surface on the right because the 
				surface on the right is hit at a sharper angle than the surface on the left. In fact, the surface on the left will
				be the brightest possible because the light there hits at an angle of 90 degrees. 
			</p>
			<p>
				The model of diffuse light is actually based on <a href="http://en.wikipedia.org/wiki/Lambert%27s_cosine_law">Lambert's 
				cosine law</a> that says that the intensity of light reflected from a surface is directly proportional to the 
				cosine of the angle between the observer's line of sight and the surface normal. Note that we changed this a bit by
				using the direction of light instead of the observer's line of sight (which we will use in specular light).
			</p>
			<p>
				To calculate the intensity of light in the diffuse model we are going to simply use the cosine of the angle between
				the light and the surface normal (whereas Lambert's law refers to the more general concept of 'directionaly 
				proportional'). Consider the following picture:
			</p>
			<p>
				<img class="center" src="http://ogldev.atspace.co.uk/www/tutorial18/lambert_law.png">
			</p>
			<p>
				We see four light rays hitting the surface at different angles. The surface normal is the green arrow pointing out
				from the surface. Light ray A has the greatest strength. The angle between A and the normal is zero and the cosine
				of zero is 1. This means that after we multiply the intensity of light (three channels of 0 to 1) by the color
				of the surface we will multiply by 1. We can't get any better than this with diffuse light. Light ray B hits the 
				surface at an angle between 0 and 90. This means that the angle between B and the normal is also between 0 and 90
				and the cosine of that angle is between 0 and 1. We will scale the result of the multiplication above by the cosine
				of that angle which means the intensity of light will definitely be less than light ray A.
			</p>
			<p>
				Things become different with light rays C and D. C hits the surface directly from the side, at an angle of 0. The
				angle between C and the normal is exactly 90 degrees and the cosine is 0. This results in C having no effect on
				lighting the surface at all! The angle between D and the normal is obtuse which means the cosine is some negative
				number which is smaller than 0 and larger or equal to -1. The end result is the same as C - no effect on the surface
				brightness.
			</p>
			<p>
				From this discussion we draw an important conclusion - in order to have any effect on the brightness of a surface
				the light must hit the surface such that the angle between it and the surface normal will be greater or equal to 
				zero and up to (but not including!) 90 degrees.
			</p>
			<p>
				We see that the surface normal plays an important part in the calculation of diffuse light. The examples above
				were very simple - the surface was a single line and there was only one normal to consider. In the real world
				we have objects that are composed of multiple polygon and the normal of each polygon is a bit different than
				the one next to it. Here's an example:
			</p>
			<p>
				<img class="center" src="http://ogldev.atspace.co.uk/www/tutorial18/normals.png">
			</p>
			<p>
				Since the normal is the same across the face of a polygon, it is enough to calculate the diffuse light in the vertex
				shader. All the three vertices in a triangle would have the same color and this will be the color of the entire 
				triangle. However, this won't look too good. We will have a bunch of polygons where each one has a particular color
				which is slightly different than the one next to it and we will see how color breaks at the edges. This can definitely
				be improved. 
			</p>
			<p>
				The trick is to use a concept known as a 'vertex normal'. A vertex normal is the average of the normals of all 
				the triangles that share the vertex. Instead of having the vertex shader calculate the diffuse light we only pass
				through the vertex normal as an attribute to the fragment shader and nothing more. The rasterizer will get three 
				different normals and will need to interpolate between them. The fragement shader will be invoked for each pixel
				with the specific normal for this pixel. We can then calculate the diffuse light at the pixel level using that
				specific normal. The result will be a lighting effect which nicely changes across the triangle face and between
				neighboring triangles. This technique is known as <a href="http://en.wikipedia.org/wiki/Phong_shading">Phong Shading</a>.
				Here's how the vertex normals look like after interpolation:
			</p>
				<img class="center" src="http://ogldev.atspace.co.uk/www/tutorial18/vertex_normals.png">
			<p>
			        You may find the pyramid model that we have been using in the last few tutorials a bit strange looking with
			        those vertex normals and decide to stick with the original normals. This is OK. However, as models become more
			        complex (and we will see that in the future) and their surfaces become smoother I think you will find the vertex
			        normals more appropriate.
			</p>
			<p>
				The only thing left to worry about is the coordinate space in which diffuse lighting calculations are going to take
				place. The vertices and their normals are specified in a local coordinate space and are transformed in the vertex 
				shader all the way to clip space by the WVP matrix that we supply to the shader. However, specifying the direction 
				of light in world space is the most logical course of action. After all, the direction of light is the result of 
			 	some light source which is positioned in the world somewhere (even the sun is located in the "world", albeit many 
			 	miles away) and sheds its light in a particular direction. Therefore, we will need to transform the normals to
			 	world space before the calculation. 
			</p>
		</section>

		<section>
			<h3> Source walkthru </h3>

			<p>(lighting_technique.h:25)</p>
			<code>
			struct DirectionalLight<br>
			{<br>
			&nbsp; &nbsp;    Vector3f Color;<br>
			&nbsp; &nbsp;    float AmbientIntensity;<br>
			&nbsp; &nbsp;    Vector3f Direction;<br>
			&nbsp; &nbsp;    float DiffuseIntensity;<br>
			};
			</code>
			<p>
				This is the new DirectionalLight structure. There are two new members here: the direction is a 3 dimensional vector
				specified in world space and the intensity is a floating point number (will be used in the same way as the ambient
				intensity).
			</p>
			<p>(lighting.vs)</p>
			<code>
			#version 330<br>
			<br>
			layout (location = 0) in vec3 Position;<br>
			layout (location = 1) in vec2 TexCoord;<br>
			layout (location = 2) in vec3 Normal;<br>
			<br>
			uniform mat4 gWVP;<br>
			uniform mat4 gWorld;<br>
			<br>
			out vec2 TexCoord0;<br>
			out vec3 Normal0;<br>
			<br>
			void main()<br>
			{<br>
			&nbsp; &nbsp;     gl_Position = gWVP * vec4(Position, 1.0);<br>
			&nbsp; &nbsp;     TexCoord0 = TexCoord;<br>
			&nbsp; &nbsp;     Normal0 = (gWorld * vec4(Normal, 0.0)).xyz;<br>
			}
			</code>
			<p>
				This is the updated vertex shader. We have a new vertex attribute, the normal, that the application will need to
				supply. In addition, the world transformation has its own uniform variable and we will need to supply it in addition
				to the WVP matrix. The vertex shader transforms the normal to world space using the world matrix and passes it to 
				the fragment shader. Note how the 3 dimensional normal is extended to a 4 dimensional vector, multiplied by 
				the 4 dimensional world matrix and then reduced back to 3 dimensions using the notation (...).xyz. This capability 
				of the GLSL language is called 'swizzling' and allows great flexibility in vector manipulations. For example, if you 
				have a 3 dimensional vector v(1,2,3) you can write: vec4 n = v.zzyy and then vector n will contain (3,3,2,2). Remember 
				that when we extend the normal from 3 to 4 dimensions we must place zero at the fourth component. This nullifies the
				effect of translation in the world matrix (the fourth column). The reason is that vectors cannot be moved like points.
				They can only be scaled or rotated. 
			</p>
			<p>(lighting.fs:1)</p>
			<code>
			#version 330<br>
			<br>
			in vec2 TexCoord0;<br>
			in vec3 Normal0;<br>
			<br>
			out vec4 FragColor;<br>
			<br>
			struct DirectionalLight<br>
			{<br>
			&nbsp; &nbsp;      vec3 Color;<br>
			&nbsp; &nbsp;      float AmbientIntensity;<br>
			&nbsp; &nbsp;      float DiffuseIntensity;<br>
			&nbsp; &nbsp;      vec3 Direction;<br>
			};
			</code>
			<p>
				Here is the beginning of the fragment shader. It now receives the interpolated vertex normal that was transformed
				by the vertex shader to world space. The DirectionalLight structure was extended to match the one in the C++ code
				and contains the new light attributes.
			</p>
			<p>(lighting.fs:19)</p>
			<code>
			void main()<br>
			{<br>
			&nbsp; &nbsp;  vec4 AmbientColor = vec4(gDirectionalLight.Color * gDirectionalLight.AmbientIntensity, 1.0f);<br>
			</code>
			<p>
				There is no change in the calculation of the ambient color factor. We calculate and store it here and use it in the
				final formula below.
			</p>
			<code>
			&nbsp; &nbsp;     float DiffuseFactor = dot(normalize(Normal0), -gDirectionalLight.Direction);<br>
			</code>    
			<p>
				This is the core of the diffuse light calculation. We calculate the cosine of the angle between the light vector
				and the normal by doing a dot product between them. There are three things to note here:
			<ol>
				<li>
					The normal passed from the vertex shader is normalized before it is used. This is because the interpolation
					the vector went through may have changed its length and it is no longer a unit vector.
				</li>
				<li>
					The light direction is reversed. If you think about this for a moment you will see that light that hits a 
					surface at a right angle is actualy 180 degrees away from the surface normal (which simply points back at the
					light source). By reversing the direction of light in this case we get a vector which equals the normal. Therefore,
					the angle between them is zero, which is what we want.
				</li>
				<li>
					The light vector is not normalized. It will be a waste of GPU resources to normalize the same vector over and
					over again for all pixels. Instead, we make sure we normalize the vector the application passes is normalized
					before the draw call is made.
				</li>		
			</ol>
			</p>
			<code>
			&nbsp; &nbsp;     vec4 DiffuseColor;<br>
			<br>
			&nbsp; &nbsp;     if (DiffuseFactor > 0) {<br>
			&nbsp; &nbsp; &nbsp; &nbsp; DiffuseColor = vec4(gDirectionalLight.Color * gDirectionalLight.DiffuseIntensity * DiffuseFactor, 1.0f);<br>
			&nbsp; &nbsp;     }<br>
			&nbsp; &nbsp;     else {<br>
			&nbsp; &nbsp; &nbsp; &nbsp;  DiffuseColor = vec4(0, 0, 0, 0);<br>
			&nbsp; &nbsp;     }<br>
			<br>
			</code>
			<p>
				Here we calculate the diffuse term which depends on the color of light, the diffuse intensity and the direction of
				light. If the diffuse factor is negative or equals to zero it means that light strikes the surface at an obtuse angle 
				(either "from the side" or "from behind"). In that case the diffuse light has no effect and the DiffuseColor vector is initialized to zero.
				If the angle is greater than zero we calculate the diffuse color by multiplying the basic light color by the 
				constant diffuse intensity and then scaling the result by the diffuse factor. If the angle between the light and
				the normal is 0 the diffuse factor will be 1 which will provide the maximum light strength.
			</p>
			<code>
			&nbsp; &nbsp;     FragColor = texture2D(gSampler, TexCoord0.xy) * (AmbientColor + DiffuseColor);<br>
			}	
			</code>
			<p>
				This is the final lighting calculation. We add the ambient and diffuse terms and multiply the result by the color
				which is sampled from the texture. Now you can see that even if diffuse light has no effect on the surface (due
				to direction), the ambient light can still light it up, if it exists.
			</p>
			<p>(lighting_technique.cpp:144)</p>
			<code>
			void LightingTechnique::SetDirectionalLight(const DirectionalLight& Light)<br>
			{<br>
			&nbsp; &nbsp;     glUniform3f(m_dirLightLocation.Color, Light.Color.x, Light.Color.y, Light.Color.z);<br>
			&nbsp; &nbsp;     glUniform1f(m_dirLightLocation.AmbientIntensity, Light.AmbientIntensity);<br>
			&nbsp; &nbsp;     Vector3f Direction = Light.Direction;<br>
			&nbsp; &nbsp;     Direction.Normalize();<br>
			&nbsp; &nbsp;     glUniform3f(m_dirLightLocation.Direction, Direction.x, Direction.y, Direction.z);<br>
			&nbsp; &nbsp;     glUniform1f(m_dirLightLocation.DiffuseIntensity, Light.DiffuseIntensity);<br>
			}	
			</code>
			<p>
				This function sets the parameters of the directional light into the shader. It was extended to cover the direction
				vector and the diffuse intensity. Note that the direction vector is normalized before it is set. The LightingTechnique
				class also fetches the direction and diffuse intensity uniform locations from the shader as well as the world matrix
				uniform location. There is also a function to set the world transformation matrix. All this stuff is pretty routine 
				by now and the code is not quoted here. Check the source for more details.
			</p>
			<p>(tutorial18.cpp:35)</p>
			<code>
			struct Vertex<br>
			{<br>
			&nbsp; &nbsp; Vector3f m_pos;<br>
			&nbsp; &nbsp; Vector2f m_tex;<br>
			&nbsp; &nbsp; Vector3f m_normal;<br>
			<br>
			&nbsp; &nbsp; Vertex() {}<br>
			<br>
			&nbsp; &nbsp; Vertex(Vector3f pos, Vector2f tex)<br>
			&nbsp; &nbsp; {<br>
			&nbsp; &nbsp; &nbsp; &nbsp; m_pos    = pos;<br>
			&nbsp; &nbsp; &nbsp; &nbsp; m_tex    = tex;<br>
			&nbsp; &nbsp; &nbsp; &nbsp; m_normal = Vector3f(0.0f, 0.0f, 0.0f);<br>
			&nbsp; &nbsp; }<br>
			};
			</code>
			<p>
				The updated Vertex structure now includes the normal. It is initialized automatically to zero by the constructor
				and we have a dedicated function that scans all the vertices and calculates the normals.
			</p>
			<p>(tutorial18.cpp:197)</p>
			<code>
			void CalcNormals(const unsigned int* pIndices, unsigned int IndexCount, Vertex* pVertices, unsigned int VertexCount)<br>
			{<br>
			&nbsp; &nbsp; for (unsigned int i = 0 ; i &lt; IndexCount ; i += 3) {<br>
			&nbsp; &nbsp; &nbsp; &nbsp; unsigned int Index0 = pIndices[i];<br>
			&nbsp; &nbsp; &nbsp; &nbsp; unsigned int Index1 = pIndices[i + 1];<br>
			&nbsp; &nbsp; &nbsp; &nbsp; unsigned int Index2 = pIndices[i + 2];<br>
			&nbsp; &nbsp; &nbsp; &nbsp; Vector3f v1 = pVertices[Index1].m_pos - pVertices[Index0].m_pos;<br>
			&nbsp; &nbsp; &nbsp; &nbsp; Vector3f v2 = pVertices[Index2].m_pos - pVertices[Index0].m_pos;<br>
			&nbsp; &nbsp; &nbsp; &nbsp; Vector3f Normal = v1.Cross(v2);<br>
			&nbsp; &nbsp; &nbsp; &nbsp; Normal.Normalize();<br>
			<br>
			&nbsp; &nbsp; &nbsp; &nbsp; pVertices[Index0].m_normal += Normal;<br>
			&nbsp; &nbsp; &nbsp; &nbsp; pVertices[Index1].m_normal += Normal;<br>
			&nbsp; &nbsp; &nbsp; &nbsp; pVertices[Index2].m_normal += Normal;<br>
			&nbsp; &nbsp;     }<br>
			<br>
			&nbsp; &nbsp;     for (unsigned int i = 0 ; i &lt; VertexCount ; i++) {<br>
			&nbsp; &nbsp; &nbsp; &nbsp;         pVertices[i].m_normal.Normalize();<br>
			&nbsp; &nbsp;     }<br>
			}
			</code>
			<p>
				This function takes an array of vertices and indices, fetches the vertices of each triangle according to the indices
				and calculates its normal. In the first loop we only accumulate the normals into each of the three triangle vertices.
				For each triangle the normal is calculated as a cross product between the two edges that are coming out of the first
				vertex. Before accumulating the normal in the vertex we make sure we normalize it. The reaons is that the result of the
				cross product is not guaranteed to be of unit length. In the second loop we scan the array of vertices directly (since 
				we don't care about the indices any more) and normalize the normal of each vertex. This operation is equivalent to averaging 
				out the accumulated sum of normals and	leaves us with a vertex normal that is of a unit length. This function is called 
				before the vertex buffer is created	in order to get the calculated vertex normals into the buffer along with the other vertex attributes.
			</p>
			<p>(tutorial18.cpp:131)</p>
			<code>
			&nbsp; &nbsp; const Matrix4f&amp; WorldTransformation = p.GetWorldTrans();<br>
			&nbsp; &nbsp; m_pEffect->SetWorldMatrix(WorldTransformation);<br>
			&nbsp; &nbsp; ...<br>
			&nbsp; &nbsp; glEnableVertexAttribArray(2);<br>
			&nbsp; &nbsp; ...<br>
			&nbsp; &nbsp; glVertexAttribPointer(2, 3, GL_FLOAT, GL_FALSE, sizeof(Vertex), (const GLvoid*)20);<br>
			&nbsp; &nbsp; ...<br>
			&nbsp; &nbsp; glDisableVertexAttribArray(2);<br>
			</code>
			<p>
				These are the main changes to the render loop. The pipeline class has a new function that provides the world
				transformation matrix (in addition to the WVP matrix). The world matrix is calculated as the multiplication of the
				scaling matrix by the rotation matrix and finally by the translation matrix. We enable and disable the third
				vertex attribute array and specify the offset of the normal within each vertex in the vertex buffer. The offset
				is 20 because the normal is preceded by the position (12 bytes) and the texture coordinates (8 bytes).
			</p> 
			<p>
				To complete the demo that we see in this tutorial's picture we must also specify the diffuse intensity and the light
				direction. This is done in the constructor of the Tutorial18 class. The diffuse intensity is set to 0.8 and the
				direction of light is from left to right. The ambient intensity was decreased all the way down to zero to amplify
				the effect of diffuse light. You can play with the keys 'z' and 'x' to control the diffuse intensity (as well as
				'a' and 's' from the previous tutorial that governs ambient intensity).
			</p>
			<p>
			    <b>Mathematical note</b><br>
			There are many sources online that tell you that you need the transpose of the inverse of the world matrix 
			in order to transform the normal vector. This is correct, however, we usually don't need to go
			that far. Our world matrices are always orthogonal (their vectors are always orthogonal). Since the inverse
			of an orthogonal matrix is equal to its transpose, the transpose of the inverse is actually the transpose
			of the transpose, so we end up with the original matrix. As long as we avoid doing distortions (scaling one
			axis differently than the rest) we are fine with the approach I presented above.
			</p>
		</section>

		<a href="../tutorial19/tutorial19.html" class="next highlight"> Next tutorial </a>
	</article>

	<script src="../html5shiv.min.html"></script>
	<script src="../html5shiv-printshiv.min.html"></script>
</body>

Providence Salumu
</html>